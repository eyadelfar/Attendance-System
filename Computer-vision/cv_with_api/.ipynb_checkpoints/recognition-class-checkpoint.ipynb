{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fefefa8-3ca9-46ec-880f-f8a56a9757df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eyada\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2, os, pickle, uuid\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "from deepface import DeepFace\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a1f6a-72e9-487a-9360-9a14008fd296",
   "metadata": {},
   "source": [
    "db, session , course , lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72492c26-c2e9-448c-87c0-d1ab24448da7",
   "metadata": {},
   "source": [
    "load_encodings, retrain, #joined attendance # left attendance -> preprocess for recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ade2a-95dc-48bb-b240-9465ad832eef",
   "metadata": {},
   "source": [
    "recognize -> recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a403889-5d49-43e2-b7fd-1e501dfdaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognition:\n",
    "    def __init__(self, db, session_id, course_id,lecture_id,status):\n",
    "        self.db = db\n",
    "        self.session_id = session_id\n",
    "        self.course_id = course_id\n",
    "        self.lecture_id = lecture_id\n",
    "        self.confidence_threshold = 0.6\n",
    "        self.status = status\n",
    "\n",
    "        self.load_encodings()\n",
    "    def load_encodings(self):\n",
    "        if os.path.exists('known_encodings.pkl'):\n",
    "            with open('known_encodings.pkl', 'rb') as f:\n",
    "                self.results = pickle.load(f)\n",
    "                self.known_encodings = [result[1] for result in self.results]\n",
    "                self.file_paths = [result[0] for result in self.results]\n",
    "        else:\n",
    "            self.results = []\n",
    "            self.known_encodings = []\n",
    "            self.file_paths = []\n",
    "\n",
    "\n",
    "    def retrain(self, augment=False, save_augments=False,n_samples=2):\n",
    "        def augment_image(img):\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.Affine(rotate=(-15, 15)),  # Random rotation\n",
    "                iaa.Fliplr(0.5),  # Horizontal flip\n",
    "                iaa.MultiplyBrightness((0.4, 1.5)),  # Random brightness\n",
    "                iaa.GammaContrast((0.5, 1.5)),  # Gamma contrast\n",
    "                iaa.Affine(scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}),  # Random scaling\n",
    "                iaa.Affine(shear=(-7, 7))  # Random shear\n",
    "            ])\n",
    "            if augment:\n",
    "                augmented_img = seq.augment_image(img)\n",
    "                return augmented_img\n",
    "            else:\n",
    "                return img\n",
    "    \n",
    "        def process_folder(student_folder):\n",
    "            student_id = os.path.basename(student_folder)\n",
    "            print(student_id)\n",
    "            image_files = [os.path.join(student_folder, file) for file in os.listdir(student_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            encodings = []\n",
    "    \n",
    "            for img_path in image_files:\n",
    "                img = cv2.imread(img_path)\n",
    "    \n",
    "                if augment:\n",
    "                    augmented_images = [img]  # Include original image\n",
    "                    for _ in range(n_samples):  # Generate additional samples\n",
    "                        augmented_images.append(augment_image(img))\n",
    "                else:\n",
    "                    augmented_images = [img]\n",
    "    \n",
    "                for idx, augmented_img in enumerate(augmented_images):\n",
    "                    encoding = DeepFace.represent(augmented_img, model_name='VGG-Face', enforce_detection=False)\n",
    "                    if encoding:\n",
    "                        encodings.append((img_path, encoding[0]['embedding']))\n",
    "    \n",
    "                        if save_augments and augment:  # Save augmented images if enabled\n",
    "                            filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                            augmented_filename = f\"augmented_{filename}_{idx}.jpg\"\n",
    "                            cv2.imwrite(os.path.join(student_folder, augmented_filename), augmented_img)\n",
    "    \n",
    "            return encodings\n",
    "    \n",
    "        db_folder = 'db'\n",
    "        student_folders = [os.path.join(db_folder, folder) for folder in os.listdir(db_folder) if os.path.isdir(os.path.join(db_folder, folder))]\n",
    "    \n",
    "        self.results = []\n",
    "        for student_folder in student_folders:\n",
    "            self.results.extend(process_folder(student_folder))\n",
    "    \n",
    "        # Save computed embeddings and corresponding file paths\n",
    "        with open('known_encodings.pkl', 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "    \n",
    "        self.load_encodings()\n",
    "\n",
    "\n",
    "    def mark_attendance(self, student_id):\n",
    "        # Marks attendance for a recognized student in the database\n",
    "        try:\n",
    "            cursor = self.db.cursor()\n",
    "            # Fetch student's name from the database based on the student_id\n",
    "            sql = \"SELECT fullname FROM student_details WHERE student_id = %s\"\n",
    "            val = (student_id,)\n",
    "            cursor.execute(sql, val)\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                student_name = result[0]\n",
    "            # Check if the student has already been marked present for the given course, session, and lecture\n",
    "            sql = \"SELECT * FROM attendance WHERE student_id = %s AND course_id = %s AND session_id = %s AND lecture_id = %s\"\n",
    "            val = (student_id, self.course_id, self.session_id, self.lecture_id)\n",
    "            cursor.execute(sql, val)\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                attendance_status = f\"Attendance already taken for {student_name}\"\n",
    "                return\n",
    "            else:\n",
    "                sql = \"INSERT INTO attendance (course_id, session_id, lecture_id, timestamp, status, student_id) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                val = (self.course_id, self.session_id, self.lecture_id, datetime.now(), self.status, student_id)\n",
    "                cursor.execute(sql, val)\n",
    "                self.db.commit()\n",
    "                cursor.close()\n",
    "        except mysql.connector.Error as err:\n",
    "            print(f\"Database error: {err}\")\n",
    "\n",
    "    \n",
    "    def recognize(self, max_images=0, video_source=0):\n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        \n",
    "        while True:\n",
    "            success, img = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "    \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "            for (x, y, w, h) in faces:\n",
    "                face_img = img[y:y+h, x:x+w]\n",
    "                face_encoding = DeepFace.represent(face_img, model_name='VGG-Face', enforce_detection=False, detector_backend='yolov8')\n",
    "                if face_encoding:\n",
    "                    face_encoding = face_encoding[0]['embedding']\n",
    "    \n",
    "                    best_match_id = None\n",
    "                    confidence = 0.0\n",
    "    \n",
    "                    for j, known_encoding in enumerate(self.known_encodings):\n",
    "                        if len(known_encoding) == len(face_encoding):\n",
    "                            result = DeepFace.verify(known_encoding, face_encoding, model_name='VGG-Face', silent=True, detector_backend='yolov8')\n",
    "                            if result['verified'] and result['distance'] < self.confidence_threshold:\n",
    "                                best_match_id = os.path.basename(os.path.dirname(self.file_paths[j]))\n",
    "                                confidence = 1 - result['distance']  \n",
    "                                break\n",
    "    \n",
    "                    # Fetch student's name from the database based on student ID\n",
    "                    student_name = None\n",
    "                    if best_match_id:\n",
    "                        cursor = self.db.cursor()\n",
    "                        sql = \"SELECT fullname FROM student_details WHERE student_id = %s\"\n",
    "                        val = (best_match_id,)\n",
    "                        cursor.execute(sql, val)\n",
    "                        result = cursor.fetchone()\n",
    "                        if result:\n",
    "                            student_name = result[0]\n",
    "                        self.mark_attendance(best_match_id)\n",
    "                        if student_name:\n",
    "                            attendance_status = f\"Attendance taken ({confidence:.2f} confidence)\"\n",
    "                            # Save the successful recognition image to the student's folder\n",
    "                            student_folder = os.path.join('db', best_match_id)\n",
    "                            try:\n",
    "                                image_files = [os.path.join(student_folder, file) for file in os.listdir(student_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                                num_images_in_folder = len(image_files)\n",
    "                                if num_images_in_folder < max_images:  # Limit the number of images per student folder\n",
    "                                    unique_filename = str(uuid.uuid4()) + '.jpg'\n",
    "                                    cv2.imwrite(os.path.join(student_folder, unique_filename), face_img)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error saving recognition image to folder {student_folder}: {e}\")\n",
    "                    else:\n",
    "                        attendance_status = \"Attendance not taken\"\n",
    "    \n",
    "                    # Draw rectangle and label with attendance status and student's name\n",
    "                    color = (0, 255, 0) if best_match_id else (0, 0, 255)\n",
    "                    cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "                    cv2.putText(img, attendance_status, (x, y-10), cv2.FONT_ITALIC, 0.9, color, 2)\n",
    "                    if best_match_id and student_name:\n",
    "                        cv2.putText(img, student_name, (x, y+h+20), cv2.FONT_ITALIC, 0.9, color, 2)\n",
    "    \n",
    "            cv2.imshow(\"Faces with Rectangles\", img)\n",
    "    \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "    \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d54954-f0c3-4d84-8afc-a353ecbd809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'joined', 'left'\n",
    "session_id = 2\n",
    "course_id = 2\n",
    "lecture_id = 1\n",
    "status = 'joined'\n",
    "# Example usage:\n",
    "db_smp = mysql.connector.connect(\n",
    "        host=\"127.0.0.1\",\n",
    "        user=\"root\",\n",
    "        password=\"e@123321xzX\",\n",
    "        port=3306,\n",
    "        database=\"attendance\"\n",
    "    )\n",
    "\n",
    "recognition = Recognition(db_smp, session_id, course_id,lecture_id,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9121914e-41f6-446e-92e7-7c4318219d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "recognition.retrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84f1870-b91a-4ea3-996e-f3526c27ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition.recognize(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67b12b-5786-4a0f-a4c2-6a2257eb61f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
